---
layout: post
title: "よく忘れるシリーズ Apache Spark版"
excerpt: ""
categories: 技術
tags: [Apache Spark]
comments: false
---
![]({{ site.baseurl}}/images/page_headder/programming.jpg)<br><br>
## 1. はじめに
筆者が忘れるシリーズのSpark版です。  
どうも、JavaでのDataFlameのJoinの仕方を忘れてしまいます。  
<br>

## 2. 環境
本記事は、以下の環境で動作は確認しています。

>・Amazon Linux  
・Ubuntu  

<br>
## 3. いつも忘れてしまう方々
コーディングが止まってしまい、困っちゃいます。  
<br>

## Import
以下をインポートしましょう。

```java
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row
```
<br>

## Filter
条件を絞って、行を出力します。  

```java
Dataset<Row> dfResult = dfSource.filter("{列名}='{条件}'");
```
もちろん ANDしたり、
```java
Dataset<Row> dfResult = dfSource
	.filter("{列名}='{条件}' AND {列名}='{条件}'");
```
ORやNOTしたりもできます。
```java
Dataset<Row> dfResult = dfSource
	.filter("{列名}='{条件}' OR {列名}<>'{条件}'");
```
<br>

## Join
Joinです。

```java
Dataset<Row> dfResult = dfSource1
	.join(dfSource2,
	      dfSource1.col("{列名}").equalTo(dfSource2.col("{列名}")))
```
<br>

## 列名の変更
Joinして列名が同じになったりした時に、列名を変えれます。

```java
Dataset<Row> dfResult = dfSource1
	.withColumnRenamed("{旧列名}", "{新列名}");
```
<br>

## 重複列の削除
JoinするとID項目なんかが二重になっちゃいますが、それをひとつにしてくれます。

```java
Dataset<Row> dfResult = dfResult.dropDuplicates("{新列名}");
```
もしくは
```java
Dataset<Row> dfResult = dfResult.distinct();
```
<br>

## 4. 終わりに
個人的にですけど、Spark は Pythonで使うのが良いですかね。  

{% include page_footer.md %}
